{"cells":[{"cell_type":"markdown","id":"3ec8b698","metadata":{"id":"3ec8b698"},"source":["# AI Capstone Project 15B - CartPole Data Preparation\n","## 1. Dependencies\n","Please uncomment below code lines and install packages if you run this notebook for the first time.  \n","You can either use Google Colab environment or your own Conda environment on a personal computer.\n","\n","Hardware Requirements:\n","- No external GPU needed (PPO uses CPU)"]},{"cell_type":"code","execution_count":1,"id":"fe2f58d4","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680692710572,"user":{"displayName":"Michelle Sun","userId":"13960667190201809247"},"user_tz":-600},"id":"fe2f58d4"},"outputs":[],"source":["# !conda install pytorch torchvision torchaudio cpuonly -c pytorch\n","# !pip install gym[classic_control]==0.21.0\n","# !pip install stable-baselines3[extra]\n","# !pip install pyglet==1.4.10\n","# !pip install moviepy"]},{"cell_type":"code","execution_count":2,"id":"d8c1534c","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1680692710575,"user":{"displayName":"Michelle Sun","userId":"13960667190201809247"},"user_tz":-600},"id":"d8c1534c"},"outputs":[],"source":["import gym\n","from tqdm import tqdm\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"id":"e990df4e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"elapsed":13,"status":"error","timestamp":1680692710576,"user":{"displayName":"Michelle Sun","userId":"13960667190201809247"},"user_tz":-600},"id":"e990df4e","outputId":"227f06e1-2928-4863-d412-a5b624cd2c64"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-602c6bd24905>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_vec_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate_policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from stable_baselines3 import PPO\n","from stable_baselines3.common.env_util import make_vec_env\n","from stable_baselines3.common.evaluation import evaluate_policy"]},{"cell_type":"markdown","id":"84dea064","metadata":{"id":"84dea064"},"source":["## 2. Train an AI Expert Agent\n","We will use the dataset generated by AI expert which will be trained through reinforcement learning.  \n","The algorithm that the AI expert uses will not be written from scratch, rather than, the agent will be trained using PPO(Proximal Policy Optimization) algorithm provided from Stable Baselines3 package.\n","\n","Our goal is training the AI expert to achieve a maximum reward score from the 'CartPole-v1' simulation on the OpenAI Gymnasium environment. From the official document the episode ends when the reward score reaches 500 points (https://gymnasium.farama.org/environments/classic_control/cart_pole/).\n"]},{"cell_type":"code","execution_count":null,"id":"b96ba249","metadata":{"id":"b96ba249"},"outputs":[],"source":["env = make_vec_env(\"CartPole-v1\", n_envs=1)"]},{"cell_type":"code","execution_count":null,"id":"7a199b6d","metadata":{"id":"7a199b6d","outputId":"d6b88bfe-2f4a-448e-b2d0-54ff37530b46","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 22       |\n","|    ep_rew_mean     | 22       |\n","| time/              |          |\n","|    fps             | 1580     |\n","|    iterations      | 1        |\n","|    time_elapsed    | 1        |\n","|    total_timesteps | 2048     |\n","---------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 24.9        |\n","|    ep_rew_mean          | 24.9        |\n","| time/                   |             |\n","|    fps                  | 1178        |\n","|    iterations           | 2           |\n","|    time_elapsed         | 3           |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.008221751 |\n","|    clip_fraction        | 0.12        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.685      |\n","|    explained_variance   | 0.00413     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 8.02        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.0184     |\n","|    value_loss           | 53.4        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 35.8       |\n","|    ep_rew_mean          | 35.8       |\n","| time/                   |            |\n","|    fps                  | 1075       |\n","|    iterations           | 3          |\n","|    time_elapsed         | 5          |\n","|    total_timesteps      | 6144       |\n","| train/                  |            |\n","|    approx_kl            | 0.00865297 |\n","|    clip_fraction        | 0.0598     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.664     |\n","|    explained_variance   | 0.0978     |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 16         |\n","|    n_updates            | 20         |\n","|    policy_gradient_loss | -0.0161    |\n","|    value_loss           | 30.9       |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 47.9        |\n","|    ep_rew_mean          | 47.9        |\n","| time/                   |             |\n","|    fps                  | 1036        |\n","|    iterations           | 4           |\n","|    time_elapsed         | 7           |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.009704533 |\n","|    clip_fraction        | 0.0813      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.637      |\n","|    explained_variance   | 0.22        |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 23.6        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.019      |\n","|    value_loss           | 53.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 62.4        |\n","|    ep_rew_mean          | 62.4        |\n","| time/                   |             |\n","|    fps                  | 1012        |\n","|    iterations           | 5           |\n","|    time_elapsed         | 10          |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.008577866 |\n","|    clip_fraction        | 0.0771      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.603      |\n","|    explained_variance   | 0.267       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 23.7        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0194     |\n","|    value_loss           | 66.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 77.7        |\n","|    ep_rew_mean          | 77.7        |\n","| time/                   |             |\n","|    fps                  | 996         |\n","|    iterations           | 6           |\n","|    time_elapsed         | 12          |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.012337879 |\n","|    clip_fraction        | 0.0741      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.584      |\n","|    explained_variance   | 0.389       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 33.8        |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.0139     |\n","|    value_loss           | 64.4        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 94.6         |\n","|    ep_rew_mean          | 94.6         |\n","| time/                   |              |\n","|    fps                  | 988          |\n","|    iterations           | 7            |\n","|    time_elapsed         | 14           |\n","|    total_timesteps      | 14336        |\n","| train/                  |              |\n","|    approx_kl            | 0.0055354536 |\n","|    clip_fraction        | 0.0543       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.573       |\n","|    explained_variance   | 0.583        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 12.8         |\n","|    n_updates            | 60           |\n","|    policy_gradient_loss | -0.0126      |\n","|    value_loss           | 54.1         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 111          |\n","|    ep_rew_mean          | 111          |\n","| time/                   |              |\n","|    fps                  | 980          |\n","|    iterations           | 8            |\n","|    time_elapsed         | 16           |\n","|    total_timesteps      | 16384        |\n","| train/                  |              |\n","|    approx_kl            | 0.0050187116 |\n","|    clip_fraction        | 0.0373       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.577       |\n","|    explained_variance   | 0.762        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 3.16         |\n","|    n_updates            | 70           |\n","|    policy_gradient_loss | -0.00785     |\n","|    value_loss           | 37.6         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 130         |\n","|    ep_rew_mean          | 130         |\n","| time/                   |             |\n","|    fps                  | 974         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 18          |\n","|    total_timesteps      | 18432       |\n","| train/                  |             |\n","|    approx_kl            | 0.005608736 |\n","|    clip_fraction        | 0.0982      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.564      |\n","|    explained_variance   | 0.802       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 15.8        |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.0096     |\n","|    value_loss           | 38.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 148         |\n","|    ep_rew_mean          | 148         |\n","| time/                   |             |\n","|    fps                  | 970         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 21          |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.002459987 |\n","|    clip_fraction        | 0.0144      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.559      |\n","|    explained_variance   | 0.694       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 24.3        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.00349    |\n","|    value_loss           | 51.7        |\n","-----------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 164          |\n","|    ep_rew_mean          | 164          |\n","| time/                   |              |\n","|    fps                  | 967          |\n","|    iterations           | 11           |\n","|    time_elapsed         | 23           |\n","|    total_timesteps      | 22528        |\n","| train/                  |              |\n","|    approx_kl            | 0.0068453318 |\n","|    clip_fraction        | 0.0556       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.544       |\n","|    explained_variance   | 0.842        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 4.15         |\n","|    n_updates            | 100          |\n","|    policy_gradient_loss | -0.00435     |\n","|    value_loss           | 25.5         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 180          |\n","|    ep_rew_mean          | 180          |\n","| time/                   |              |\n","|    fps                  | 963          |\n","|    iterations           | 12           |\n","|    time_elapsed         | 25           |\n","|    total_timesteps      | 24576        |\n","| train/                  |              |\n","|    approx_kl            | 0.0048389696 |\n","|    clip_fraction        | 0.0474       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.551       |\n","|    explained_variance   | 0.953        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.97         |\n","|    n_updates            | 110          |\n","|    policy_gradient_loss | -0.00892     |\n","|    value_loss           | 7.23         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 199         |\n","|    ep_rew_mean          | 199         |\n","| time/                   |             |\n","|    fps                  | 960         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 27          |\n","|    total_timesteps      | 26624       |\n","| train/                  |             |\n","|    approx_kl            | 0.006570342 |\n","|    clip_fraction        | 0.0584      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.527      |\n","|    explained_variance   | 0.888       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 0.00209     |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.00683    |\n","|    value_loss           | 4.28        |\n","-----------------------------------------\n"]}],"source":["ai_expert = PPO('MlpPolicy', env, verbose=1)\n","ai_expert.learn(total_timesteps=25000)\n","ai_expert.save('ai-expert')"]},{"cell_type":"code","execution_count":null,"id":"c563d232","metadata":{"id":"c563d232"},"outputs":[],"source":["# You can load saved model if you already trained it\n","# Commenth above code block, and uncomment this block\n","ai_expert = PPO.load('ai-expert')"]},{"cell_type":"code","execution_count":null,"id":"06d9bc6b","metadata":{"id":"06d9bc6b","outputId":"c1c7e4c5-e7fe-4d7c-99e8-90dc7268cd6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean reward = 500.0 +/- 0.0\n"]}],"source":["# Evaluate the trained AI expert\n","mean_reward, std_reward = evaluate_policy(ai_expert, env, n_eval_episodes=10)\n","print(f'Mean reward = {mean_reward} +/- {std_reward}')"]},{"cell_type":"markdown","id":"0c287e34","metadata":{"id":"0c287e34"},"source":["## 3. Recording Demonstrations\n","In this part, we will record demonstrations from the AI expert on the OpenAI Gymnasium environment.  \n"]},{"cell_type":"code","execution_count":null,"id":"b4d19759","metadata":{"id":"b4d19759"},"outputs":[],"source":["recording_env = gym.wrappers.Monitor(gym.make('CartPole-v1', render_mode='rgb_array'), 'sample-video', video_callable=lambda episode_id: True, force=True)"]},{"cell_type":"code","execution_count":null,"id":"614cd6c0","metadata":{"id":"614cd6c0","outputId":"9d43fb1e-d3e5-4c3d-da3a-a79bb19a005b"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:43<00:00,  8.65s/it]\n"]}],"source":["VIDEO_RECORD_TRY = 5\n","\n","for _ in tqdm(range(VIDEO_RECORD_TRY)):\n","    obs = recording_env.reset()\n","    dones = False\n","    while not dones:\n","        \n","        action, _states = ai_expert.predict(obs)\n","        obs, rewards, dones, info = recording_env.step(action)"]},{"cell_type":"markdown","id":"287ddacc","metadata":{"id":"287ddacc"},"source":["## References\n","- https://medium.com/@sthanikamsanthosh1994/imitation-learning-behavioral-cloning-using-pytorch-d5013404a9e5\n","- https://gymnasium.farama.org/environments/classic_control/cart_pole/\n","- https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html"]},{"cell_type":"code","execution_count":null,"id":"d65fab70","metadata":{"id":"d65fab70"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}
